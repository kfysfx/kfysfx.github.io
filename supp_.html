<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
	<meta http-equiv="content-type" content="text/html; charset=UTF-8" />
	<meta name="description" content="Video Event Detection" />
	<meta name="keywords" content="Constraint Flow" />	
	<meta name="author" content="Wei Zhen" />
	<link rel="stylesheet" href="css/SPR.css" type="text/css" />
	<title>Semantic Preserving Retargeting</title>
</head>

<body>
<!--------------
Title
---------->
	<div id="header">
		<div class="wrap">
		  	<div id="intro">
		    	<h1 align="center" id="logo">Semantic Preserving Retargeting</h1>
		      	<h2 align="center" id="logo">Supplementary Analysis and Visualization</h2>
          		</div>
		<div class="nline1"></div>
		</div>
	</div>
	
<!--------------
First paragraph
---------->
	<div id="cont">
		<div class="wrap">        	
            	<p align="justify" style="text-indent:2em">
This supplementary material contains three parts. First, we give qualitative comparisons between the importance maps
generated by our method and other baseline methods. Second, we show more results of our retargeting systems. Third,
we present more information on our experimental results over the Amazon Mechanical Turk (AMT) platform. In all of our
experiments, the original images are resized to half of their widths while keeping their heights unchanged.
            	</p>
		<div class="line"></div>
      		</div>
    	</div>

<!--------------
1.
---------->
	<div id="cont">
		<div class="wrap">
			<h2 id="subject">Comparisons on importance maps</h2>
			<p align="justify" style="text-indent:2em"> 
			</p>
	<div class="line"></div>
        </div>
</div>
	
<!--------------
2.
---------->
	<div id="cont">
		<div class="wrap">
			<h2 id="subject">More comparisons with retargeting systems</h2>
			<p align="justify" style="text-indent:2em"> 
			</p>
			<p align="justify" style="text-indent:2em"> 
			</p>
			<p align="justify" style="text-indent:2em"> 
			</p>
			<p align="justify" style="text-indent:2em"> 
			</p>
			<p align="justify" style="text-indent:2em"> 
			</p>
			<p align="justify" style="text-indent:2em"> 
			</p>
			<p align="justify" style="text-indent:2em"> 
			</p>
			<p align="justify" style="text-indent:2em"> 
			</p>
	<div class="line"></div>
        </div>
</div>
	
<!--------------
3.
---------->
	<div id="cont">
		<div class="wrap">
			<h2 id="subject">More results from Amazon Mechanical Turk</h2>
			<p align="justify" style="text-indent:2em"> 
All quantitative comparisons in the paper are carried on the <a href="https://www.mturk.com/mturk"> Amazon Mechanical Turk (AMT)</a>. Our target image and
the result by a baseline are shown in randomly order to the AMT workers, who are asked to select the better one. Each pair
is compared by 3 different AMT workers, and we record the numbers of votes preferring our result than the baseline. The
comparison results are shown in the form of “A(B)” which means that in the total (A+B) comparisons, our method wins A
times while baseline wins B times. The larger gap between A and B means more advantage.
			</p>
			<!---------------------------Table 1---------------------->
			<p align="center">
		 		<strong class="fig-label">Table 1. </strong>
				Comparion between our importance map and 6 baseline maps when combined with 3 different carriers.
		  		<img src="images/SPR/supp_table_1.png" alt="" width="500" height="48" align="bottom" />
		 	</p>
			<p align="justify" style="text-indent:2em"> 
				We also collected information about the workers in our experiments on AMT. Statistical information are given below.
			</p>
			<!---------------------------Figure 7---------------------->
			<p style="text-align:center">
         			<img src="images/SPR/supp_fig_7.png" alt="" width="800" height="461" align="bottom" />
         		</p>
         		<div class="caption">
            			<p class="caption-content">
               				<strong class="fig-label">Figure 7</strong>. 
					Comparisons between our result, which generated by our importance map and the IF carrier, and 6 baseline retargeting systems. Images are selected from the category of single person.
            			</p>
			</div>
			<!---------------------------Figure 8---------------------->
			<p style="text-align:center">
         			<img src="images/SPR/supp_fig_8.png" alt="" width="800" height="461" align="bottom" />
         		</p>
         		<div class="caption">
            			<p class="caption-content">
               				<strong class="fig-label">Figure 8</strong>. 
					Comparisons between our result, which generated by our importance map and the IF carrier, and 6 baseline retargeting systems. Images are selected from the category of multiple people.
            			</p>
			</div>
			<!---------------------------Figure 9---------------------->
			<p style="text-align:center">
         			<img src="images/SPR/supp_fig_9.png" alt="" width="800" height="461" align="bottom" />
         		</p>
         		<div class="caption">
            			<p class="caption-content">
               				<strong class="fig-label">Figure 9</strong>. 
					Comparisons between our result, which generated by our importance map and the IF carrier, and 6 baseline retargeting systems. Images are selected from the category of single object.
            			</p>
			</div>
			<!---------------------------Figure 10---------------------->
			<p style="text-align:center">
         			<img src="images/SPR/supp_fig_10.png" alt="" width="800" height="461" align="bottom" />
         		</p>
         		<div class="caption">
            			<p class="caption-content">
               				<strong class="fig-label">Figure 10</strong>. 
					Comparisons between our result, which generated by our importance map and the IF carrier, and 6 baseline retargeting systems. Images are selected from the category of multiple objects.
            			</p>
			</div>
			<!---------------------------Figure 11---------------------->
			<p style="text-align:center">
         			<img src="images/SPR/supp_fig_11.png" alt="" width="800" height="461" align="bottom" />
         		</p>
         		<div class="caption">
            			<p class="caption-content">
               				<strong class="fig-label">Figure 11</strong>. 
					Comparisons between our result, which generated by our importance map and the IF carrier, and 6 baseline retargeting systems. Images are selected from the category of indoor scene.
            			</p>
			</div>
			<!---------------------------Figure 12---------------------->
			<p style="text-align:center">
         			<img src="images/SPR/supp_fig_12.png" alt="" width="800" height="461" align="bottom" />
         		</p>
         		<div class="caption">
            			<p class="caption-content">
               				<strong class="fig-label">Figure 12</strong>. 
					Comparisons between our result, which generated by our importance map and the IF carrier, and 6 baseline retargeting systems. Images are selected from the category of outdoor scene.
            			</p>
			</div>
			<!---------------------------Figure 13---------------------->
			<p style="text-align:center">
         			<img src="images/SPR/supp_fig_13.png" alt="" width="800" height="461" align="bottom" />
         		</p>
         		<div class="caption">
            			<p class="caption-content">
               				<strong class="fig-label">Figure 13</strong>. 
					Statistics of workers on AMT: Gender
            			</p>
			</div>
			<!---------------------------Figure 14---------------------->
			<p style="text-align:center">
         			<img src="images/SPR/supp_fig_14.png" alt="" width="800" height="461" align="bottom" />
         		</p>
         		<div class="caption">
            			<p class="caption-content">
               				<strong class="fig-label">Figure 14</strong>. 
					Statistics of workers on AMT: Age
            			</p>
			</div>
			<!---------------------------Figure 15---------------------->
			<p style="text-align:center">
         			<img src="images/SPR/supp_fig_15.png" alt="" width="800" height="461" align="bottom" />
         		</p>
         		<div class="caption">
            			<p class="caption-content">
               				<strong class="fig-label">Figure 15</strong>. 
					Statistics of workers on AMT: Experience
            			</p>
			</div>
			
	<div class="line"></div>
        </div>
</div>

<!--------------
Reference
---------->
	 <div id="cont">
     		<div class="wrap">
         		<h2 id="subject">References</h2>
         <ul class="ref-list" align="justify">
	 	<li class="ref-item">S. Avidan and A. Shamir. Seam carving for content aware image resizing. In TOG, 2007. </li>
		<li class="ref-item">M.-M. Cheng, N. J. Mitra, X. Huang, P. H. Torr, and S.-M. Hu. Global contrast based salient region detection. TPAMI, 2015. </li>
		<li class="ref-item">M.-M. Cheng, J. Warrell, L. Wen-Yan, S. Zheng, V. Vineet, and N. Crook. Efficient salient region detection with soft image abstraction. 2013. </li>
		<li class="ref-item">Y. Ding, J. Xiao, and J. Yu. Importance filtering for image retargeting. 2011. CVPR. </li>
		 <li class="ref-item">S. Jin and L. haibin. Scale and object aware image thumbnailing. IJCV, 2013. </li>
		 <li class="ref-item">D. Panozzo, O. Weber, and O. Sorkine. Robust image retargeting via axis-aligned deformation. In EUROGRAPHICS, 2012. </li>
		 <li class="ref-item">M. Rubinstein, A. Shamir, and S. Avidan. Improved seam carving for video retargeting. In TOG, 2008. </li>
		 <li class="ref-item">M. Rubinstein, A. Shamir, and S. Avidan. Multi-operator media retargeting. TOG, 2009. </li>
		 <li class="ref-item">C. Shen, M. Song, and Q. Zhao. Learning high-level concepts by training a deep network on eye fixations. DLUFL Workshop, in conjunction with NIPS, 2012. </li>
		 <li class="ref-item">E. Vig, M. Dorr, and D. Cox. Large-scale optimization of hierarchical features for saliency prediction in natural images. In CVPR, 2014. </li>
		 <li class="ref-item">Y.-S. Wang, C.-L. Tai, O. Sorkine, and T.-Y. Lee. Optimized scale-and-stretch for image resizing. TOG, 2008. </li>
		 <li class="ref-item">L. Wolf, M. Guttmann, and D. Cohen-Or. Non-homogeneous content-driven video-retargeting. 2007. ICCV. </li>
		 <li class="ref-item">R. Zhao, W. Ouyang, H. Li, and X. Wang. Saliency detection by multi-context deep learning. In CVPR, 2015. </li>
	    </ul>
      		</div>
 	</div>
	
</body>
</html>
