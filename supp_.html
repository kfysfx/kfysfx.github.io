<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
	<meta http-equiv="content-type" content="text/html; charset=UTF-8" />
	<meta name="description" content="Video Event Detection" />
	<meta name="keywords" content="Constraint Flow" />	
	<meta name="author" content="Wei Zhen" />
	<link rel="stylesheet" href="css/SPR.css" type="text/css" />
	<title>Semantic Preserving Retargeting</title>
</head>

<body>
<!--------------
Title
---------->
	<div id="header">
		<div class="wrap">
		  	<div id="intro">
		    	<h1 align="center" id="logo">Semantic Preserving Retargeting</h1>
		      	<h2 align="center" id="logo">Supplementary Analysis and Visualization</h2>
          		</div>
		<div class="nline1"></div>
		</div>
	</div>
	
<!--------------
First paragraph
---------->
	<div id="cont">
		<div class="wrap">        	
            	<p align="justify" style="text-indent:2em">
This supplementary material contains three parts. First, we give qualitative comparisons between the importance maps
generated by our method and other baseline methods. Second, we show more results of our retargeting systems. Third,
we present more information on our experimental results over the Amazon Mechanical Turk (AMT) platform. In all of our
experiments, the original images are resized to half of their widths while keeping their heights unchanged.
            	</p>
		<div class="line"></div>
      		</div>
    	</div>

<!--------------
1.
---------->
	<div id="cont">
		<div class="wrap">
			<h2 id="subject">Comparisons on importance maps</h2>
			<p align="justify" style="text-indent:2em"> 
			</p>
	<div class="line"></div>
        </div>
</div>
	
<!--------------
2.
---------->
	<div id="cont">
		<div class="wrap">
			<h2 id="subject">More comparisons with retargeting systems</h2>
			<p align="justify" style="text-indent:2em"> 
				We feed our importance map to the carrier IF [4] which is selected because of its excellent performance and fast speed.
We present more comparisons between our retarget results and 6 other retarget systems. These baseline retarget systems are
listed below.
			</p>
			<p align="justify" style="text-indent:2em"> 
				SOAT [5]: SOAT is a method to effectively obtain image thumbnails based on cropping and warping. It models the human
perception of thumbnail by visual acuity theory, and gets the Scale and Object Aware Saliency (SOAS) first, and then it uses
SOAS to do image thumbnailing.
			</p>
			<p align="justify" style="text-indent:2em"> 
				ISC [7]: Improved Seam Carving (ISC) is the improved version of the famous Seam Carving [1] approach for retargeting.
For the improvement, instead of using the dynamic programming approach of seam carving, ISC prefers to graph cuts. A
novel energy criterion is also used in ISC to improve the visual quality of the retargeted images.
			</p>
			<p align="justify" style="text-indent:2em"> 
				Multi-Op [8]: Multi-Operator (Multi-Op) approach provides a hybrid method of doing image retargeting. Multiple operators,
including seam carving, cropping and scaling, are used alternatively to produce the results. An image similarity
measure, named Bi-Directional Warping, is used to find the optimal path in the retargeting space.
			</p>
			<p align="justify" style="text-indent:2em"> 
				Warp [12]: Warp is a warping approach for retargeting. It first analyzes the importance of each region, and then it applies
a transformation which shrinks less important regions more than important ones. This method can work both on images and
videos.
			</p>
			<p align="justify" style="text-indent:2em"> 
				AAD [6]: Axis-Aligned Deformation (AAD) is a robust image retargeting method. To avoid harmful visual distortions,
deformations in AAD are parameterized in 1-dimension. Due to this 1-dimension parameterization, AAD only needs solving
a small quadratic program, so AAD method is very efficient.
			</p>
			<p align="justify" style="text-indent:2em"> 
				OSS [11]: Optimized Scale-and-Stretch (OSS) is a warping method which can retarget images into any aspect ratios without
harmful visual distortions. OSS works through iteratively computing optimal local scaling factors for each localized region
and then updating warped images to match these scaling factors as closely as possible. An efficient formulation for the
nonlinear optimization is also developed to do the warping function computations.
			</p>
			<p align="justify" style="text-indent:2em"> 
				Results are given below.
			</p>
			<!---------------------------Figure 1---------------------->
			<p style="text-align:center">
         			<img src="images/SPR/supp_fig_1.png" alt="" width="800" height="461" align="bottom" />
         		</p>
         		<div class="caption">
            			<p class="caption-content">
               				<strong class="fig-label">Figure 1</strong>. 
					Comparisons between our map and 6 baseline maps. Images are selected from the category of single person.
            			</p>
			</div>
			<!---------------------------Figure 2---------------------->
			<p style="text-align:center">
         			<img src="images/SPR/supp_fig_2.png" alt="" width="800" height="461" align="bottom" />
         		</p>
         		<div class="caption">
            			<p class="caption-content">
               				<strong class="fig-label">Figure 2</strong>. 
					Comparisons between our map and 6 baseline maps. Images are selected from the category of multiple people.
            			</p>
			</div>
			<!---------------------------Figure 3---------------------->
			<p style="text-align:center">
         			<img src="images/SPR/supp_fig_3.png" alt="" width="800" height="461" align="bottom" />
         		</p>
         		<div class="caption">
            			<p class="caption-content">
               				<strong class="fig-label">Figure 3</strong>. 
					Comparisons between our map and 6 baseline maps. Images are selected from the category of single object.
            			</p>
			</div>
			<!---------------------------Figure 4---------------------->
			<p style="text-align:center">
         			<img src="images/SPR/supp_fig_4.png" alt="" width="800" height="461" align="bottom" />
         		</p>
         		<div class="caption">
            			<p class="caption-content">
               				<strong class="fig-label">Figure 4</strong>. 
					Comparisons between our map and 6 baseline maps. Images are selected from the category of multiple objects.
            			</p>
			</div>
			<!---------------------------Figure 5---------------------->
			<p style="text-align:center">
         			<img src="images/SPR/supp_fig_5.png" alt="" width="800" height="461" align="bottom" />
         		</p>
         		<div class="caption">
            			<p class="caption-content">
               				<strong class="fig-label">Figure 5</strong>. 
					Comparisons between our map and 6 baseline maps. Images are selected from the category of indoor scene.
            			</p>
			</div>
			<!---------------------------Figure 6---------------------->
			<p style="text-align:center">
         			<img src="images/SPR/supp_fig_6.png" alt="" width="800" height="461" align="bottom" />
         		</p>
         		<div class="caption">
            			<p class="caption-content">
               				<strong class="fig-label">Figure 6</strong>. 
					Comparisons between our map and 6 baseline maps. Images are selected from the category of outdoor scene.
            			</p>
			</div>
	<div class="line"></div>
        </div>
</div>
	
<!--------------
3.
---------->
	<div id="cont">
		<div class="wrap">
			<h2 id="subject">More results from Amazon Mechanical Turk</h2>
			<p align="justify" style="text-indent:2em"> 
All quantitative comparisons in the paper are carried on the <a href="https://www.mturk.com/mturk"> Amazon Mechanical Turk (AMT)</a>. Our target image and
the result by a baseline are shown in randomly order to the AMT workers, who are asked to select the better one. Each pair
is compared by 3 different AMT workers, and we record the numbers of votes preferring our result than the baseline. The
comparison results are shown in the form of “A(B)” which means that in the total (A+B) comparisons, our method wins A
times while baseline wins B times. The larger gap between A and B means more advantage.
			</p>
			<!---------------------------Table 1---------------------->
			<p align="center">
		 		<strong class="fig-label">Table 1. </strong>
				Comparion between our importance map and 6 baseline maps when combined with 3 different carriers.
		  		<img src="images/SPR/supp_table_1.png" alt="" width="500" height="48" align="bottom" />
		 	</p>
			<p align="justify" style="text-indent:2em"> 
				We also collected information about the workers in our experiments on AMT. Statistical information are given below.
			</p>
			<!---------------------------Figure 7---------------------->
			<p style="text-align:center">
         			<img src="images/SPR/supp_fig_7.png" alt="" width="800" height="461" align="bottom" />
         		</p>
         		<div class="caption">
            			<p class="caption-content">
               				<strong class="fig-label">Figure 7</strong>. 
					Comparisons between our result, which generated by our importance map and the IF carrier, and 6 baseline retargeting systems. Images are selected from the category of single person.
            			</p>
			</div>
			<!---------------------------Figure 8---------------------->
			<p style="text-align:center">
         			<img src="images/SPR/supp_fig_8.png" alt="" width="800" height="461" align="bottom" />
         		</p>
         		<div class="caption">
            			<p class="caption-content">
               				<strong class="fig-label">Figure 8</strong>. 
					Comparisons between our result, which generated by our importance map and the IF carrier, and 6 baseline retargeting systems. Images are selected from the category of multiple people.
            			</p>
			</div>
			<!---------------------------Figure 9---------------------->
			<p style="text-align:center">
         			<img src="images/SPR/supp_fig_9.png" alt="" width="800" height="461" align="bottom" />
         		</p>
         		<div class="caption">
            			<p class="caption-content">
               				<strong class="fig-label">Figure 9</strong>. 
					Comparisons between our result, which generated by our importance map and the IF carrier, and 6 baseline retargeting systems. Images are selected from the category of single object.
            			</p>
			</div>
			<!---------------------------Figure 10---------------------->
			<p style="text-align:center">
         			<img src="images/SPR/supp_fig_10.png" alt="" width="800" height="461" align="bottom" />
         		</p>
         		<div class="caption">
            			<p class="caption-content">
               				<strong class="fig-label">Figure 10</strong>. 
					Comparisons between our result, which generated by our importance map and the IF carrier, and 6 baseline retargeting systems. Images are selected from the category of multiple objects.
            			</p>
			</div>
			<!---------------------------Figure 11---------------------->
			<p style="text-align:center">
         			<img src="images/SPR/supp_fig_11.png" alt="" width="800" height="461" align="bottom" />
         		</p>
         		<div class="caption">
            			<p class="caption-content">
               				<strong class="fig-label">Figure 11</strong>. 
					Comparisons between our result, which generated by our importance map and the IF carrier, and 6 baseline retargeting systems. Images are selected from the category of indoor scene.
            			</p>
			</div>
			<!---------------------------Figure 12---------------------->
			<p style="text-align:center">
         			<img src="images/SPR/supp_fig_12.png" alt="" width="800" height="461" align="bottom" />
         		</p>
         		<div class="caption">
            			<p class="caption-content">
               				<strong class="fig-label">Figure 12</strong>. 
					Comparisons between our result, which generated by our importance map and the IF carrier, and 6 baseline retargeting systems. Images are selected from the category of outdoor scene.
            			</p>
			</div>
			<!---------------------------Figure 13---------------------->
			<p style="text-align:center">
         			<img src="images/SPR/supp_fig_13.png" alt="" width="800" height="461" align="bottom" />
         		</p>
         		<div class="caption">
            			<p class="caption-content">
               				<strong class="fig-label">Figure 13</strong>. 
					Statistics of workers on AMT: Gender
            			</p>
			</div>
			<!---------------------------Figure 14---------------------->
			<p style="text-align:center">
         			<img src="images/SPR/supp_fig_14.png" alt="" width="800" height="461" align="bottom" />
         		</p>
         		<div class="caption">
            			<p class="caption-content">
               				<strong class="fig-label">Figure 14</strong>. 
					Statistics of workers on AMT: Age
            			</p>
			</div>
			<!---------------------------Figure 15---------------------->
			<p style="text-align:center">
         			<img src="images/SPR/supp_fig_15.png" alt="" width="800" height="461" align="bottom" />
         		</p>
         		<div class="caption">
            			<p class="caption-content">
               				<strong class="fig-label">Figure 15</strong>. 
					Statistics of workers on AMT: Experience
            			</p>
			</div>
			
	<div class="line"></div>
        </div>
</div>

<!--------------
Reference
---------->
	 <div id="cont">
     		<div class="wrap">
         		<h2 id="subject">References</h2>
         <ul class="ref-list" align="justify">
	 	<li class="ref-item">S. Avidan and A. Shamir. Seam carving for content aware image resizing. In TOG, 2007. </li>
		<li class="ref-item">M.-M. Cheng, N. J. Mitra, X. Huang, P. H. Torr, and S.-M. Hu. Global contrast based salient region detection. TPAMI, 2015. </li>
		<li class="ref-item">M.-M. Cheng, J. Warrell, L. Wen-Yan, S. Zheng, V. Vineet, and N. Crook. Efficient salient region detection with soft image abstraction. 2013. </li>
		<li class="ref-item">Y. Ding, J. Xiao, and J. Yu. Importance filtering for image retargeting. 2011. CVPR. </li>
		 <li class="ref-item">S. Jin and L. haibin. Scale and object aware image thumbnailing. IJCV, 2013. </li>
		 <li class="ref-item">D. Panozzo, O. Weber, and O. Sorkine. Robust image retargeting via axis-aligned deformation. In EUROGRAPHICS, 2012. </li>
		 <li class="ref-item">M. Rubinstein, A. Shamir, and S. Avidan. Improved seam carving for video retargeting. In TOG, 2008. </li>
		 <li class="ref-item">M. Rubinstein, A. Shamir, and S. Avidan. Multi-operator media retargeting. TOG, 2009. </li>
		 <li class="ref-item">C. Shen, M. Song, and Q. Zhao. Learning high-level concepts by training a deep network on eye fixations. DLUFL Workshop, in conjunction with NIPS, 2012. </li>
		 <li class="ref-item">E. Vig, M. Dorr, and D. Cox. Large-scale optimization of hierarchical features for saliency prediction in natural images. In CVPR, 2014. </li>
		 <li class="ref-item">Y.-S. Wang, C.-L. Tai, O. Sorkine, and T.-Y. Lee. Optimized scale-and-stretch for image resizing. TOG, 2008. </li>
		 <li class="ref-item">L. Wolf, M. Guttmann, and D. Cohen-Or. Non-homogeneous content-driven video-retargeting. 2007. ICCV. </li>
		 <li class="ref-item">R. Zhao, W. Ouyang, H. Li, and X. Wang. Saliency detection by multi-context deep learning. In CVPR, 2015. </li>
	    </ul>
      		</div>
 	</div>
	
</body>
</html>
